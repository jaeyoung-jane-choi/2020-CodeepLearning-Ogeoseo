{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT-final-model-arch.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1h_4SmIG1TGjxEYVnSU7ju_eR0FW_4Zx-","authorship_tag":"ABX9TyPACpjjr9+a7ajyxNzGwWDz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"V-sad_1L6eOl"},"source":["##  NLP- Bert Sentence Encoding\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEuvvYF96QS3","executionInfo":{"status":"ok","timestamp":1608295729711,"user_tz":-540,"elapsed":108510,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}},"outputId":"d30cd363-dcd5-4f3f-ca1d-6d735ab7d100"},"source":["!pip install sentence_transformers\n","from sentence_transformers import SentenceTransformer\n","# bert_model = SentenceTransformer('distilbert-multilingual-nli-stsb-quora-ranking')\n","\n","bert_model = SentenceTransformer('xlm-r-bert-base-nli-stsb-mean-tokens')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting sentence_transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/5a/6e41e8383913dd2ba923cdcd02be2e03911595f4d2f9de559ecbed80d2d3/sentence-transformers-0.3.9.tar.gz (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.7MB/s \n","\u001b[?25hCollecting transformers<3.6.0,>=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 17.3MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (4.41.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (1.19.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (3.2.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 43.8MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (20.8)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 50.2MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (3.12.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (3.0.12)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 60.3MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (0.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence_transformers) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence_transformers) (0.16.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence_transformers) (1.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence_transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.6.0,>=3.1.0->sentence_transformers) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.6.0,>=3.1.0->sentence_transformers) (2.4.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<3.6.0,>=3.1.0->sentence_transformers) (50.3.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence_transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence_transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence_transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence_transformers) (3.0.4)\n","Building wheels for collected packages: sentence-transformers, sacremoses\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.9-cp36-none-any.whl size=101035 sha256=8964feff595fcbb38173acecf34b7f85636027d9bd18a1ba5936883e71d6a3f9\n","  Stored in directory: /root/.cache/pip/wheels/fc/89/43/f2f5bc00b03ef9724b0f6254a97eaf159a4c4ddc024b33e07a\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c625673eb9fd7b422d7828a42f541ede4cef1448a116a4d81d8a3355676d8b63\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sentence-transformers sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers, sentence-transformers\n","Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.9 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.01G/1.01G [01:18<00:00, 13.0MB/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"g_csHzSL44Oa"},"source":["# # !pip install pytorch_transformers\n","# from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n","\n","# # tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","# model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n","\n","\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","\n","# text = 'I liked that book very much!'\n","# tokenized_text = tokenizer.tokenize(text)\n","# print(tokenized_text)\n","\n","# text_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n","# print('text ids:', text_ids)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1y-woJiNBrK3"},"source":["## Preparing the dataset "]},{"cell_type":"code","metadata":{"id":"LhFDYjiV67zO"},"source":["# #student_book (student, book)\n","\n","# student_book = pd.read_csv('student_book.csv')\n","# student_book.head() \n","# student_book.shape #(487, 983)\n","#book text embedding\n","# book= pd.read_csv('/content/drive/MyDrive/명륜이의 서재/DATA/1206_data/재영 부분/book_100000_196940(wo null).csv') #this is the data we crawled\n","# text_book = pd.read_csv('book.csv')\n","# text_book.shape \n","# # book.head()\n","# text_book.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUYKrp98CnvD"},"source":["# #match the title and id \n","# book = book[['book_id', 'subject']]\n","# book = book.drop_duplicates('book_id')\n","# book.head()#(66660, 2)\n","# text_book['title'] = book[:1000]['subject']\n","# text_book.head()\n","# text_book =text_book.drop_duplicates('book_id')\n","# text_book =text_book.reset_index(drop=True)\n","# text_book.head()\n","# text_book.iloc[815:]\n","# text_book= text_book.sort_values('book_id')\n","# text_book.head()\n","#needs reset of index \n","# sentence_embeddings = bert_model.encode(text_book['title'])\n","# sentence_embeddings.shape #(6, 768) #this is the text embeddings for each book\n","\n","#genre embedding \n","# text_book =text_book.drop_duplicates('book_id')\n","# text_book= text_book.sort_values('book_id')\n","# text_book =text_book.reset_index(drop=True)\n","# genre =text_book[['book_id','ddc-sort']]\n","# genre.shape #(983, 2)\n","# genre = genre.set_index('book_id')\n","# genre.head()\n","# # genre['ddc-sort'].value_counts()\n","# from sklearn.preprocessing import OneHotEncoder\n","# enc = OneHotEncoder()\n","# enc.fit(genre[['ddc-sort']])\n","# genre_initial= enc.transform(genre[['ddc-sort']]).toarray()\n","# genre_initial"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5R547ofIuJAO"},"source":["## Start From Here! \n"]},{"cell_type":"code","metadata":{"id":"OEepUJ4TBzJl","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"error","timestamp":1608295729716,"user_tz":-540,"elapsed":106020,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}},"outputId":"c8eb8558-32b3-4358-804c-3ff65c7b9905"},"source":["student = pd.read_csv('student-3.csv')\n","book = pd.read_csv('bookexample.csv')\n","book.head()"],"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-c27da27e3483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'student-3.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bookexample.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"-3ixiUspx_Cj"},"source":["### 1. Find the longest/average length for the books read for each student\n"]},{"cell_type":"code","metadata":{"id":"FSSk_T2eOSzk","executionInfo":{"status":"aborted","timestamp":1608295729714,"user_tz":-540,"elapsed":80402,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}}},"source":["\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","sequences = student['booklist']\n","max_len = 55\n","\n","print('문장의 최대 길이 :',max(len(l) for l in sequences)) #10 \n","print('문장의 평균 길이 :',sum(map(len, sequences))/len(sequences))\n","plt.hist([len(s) for s in sequences], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ruBrVwDNyE5J"},"source":["### 2. Change the y value to a new df where all the values are one-hot-encoded \n"]},{"cell_type":"code","metadata":{"id":"7BtDjW7wN82c","executionInfo":{"status":"aborted","timestamp":1608295729715,"user_tz":-540,"elapsed":76801,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}}},"source":["from tensorflow.keras.utils import to_categorical\n","y = student[['pred']] #(252,)\n","train_y = pd.DataFrame(index=y.index,columns=range(0,983))\n","train_y.fillna(0, inplace=True)\n","\n","for i in range(len(y)):\n","  # print(y.iloc[i,0])\n","  train_y.iloc[i,int(y.iloc[i,0])] = 1 \n","\n","\n","train_y.head()\n","# train_y.shape #(252, 983)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NBNvzSoWyWTQ"},"source":["### 3. Make the book list into a list of lists + padd according to max_value"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"_6Bv6y90PMX_","executionInfo":{"status":"error","timestamp":1608295768724,"user_tz":-540,"elapsed":738,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}},"outputId":"8dae1938-483c-451d-a14e-66cdaf6f5718"},"source":["books = student['booklist'].tolist()\n","type(books[0])\n","books\n","new=[]\n","from ast import literal_eval\n","for x in books:\n","  x = literal_eval(x)\n","  new.append(x)\n","\n","new[:10]"],"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-64a47a620def>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'booklist'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mast\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'student' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJsfpGpNOMlK","executionInfo":{"status":"ok","timestamp":1608267545145,"user_tz":-540,"elapsed":951,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}},"outputId":"1e1204be-cc26-42ee-8954-70e2c628a2cb"},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","pad_new = pad_sequences(new, maxlen = max_len)\n","pad_new.shape #(252, 55)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(252, 55)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"E70_wooHyjE1"},"source":["### 4. Embedd the titles using bert - get the embeddings "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4sj5-I_CSSqO","executionInfo":{"status":"ok","timestamp":1608267744810,"user_tz":-540,"elapsed":737,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}},"outputId":"d26e3b7e-bfd3-4252-fdec-3162313998ea"},"source":["\n","# book.shape #(983, 5)\n","# book.head()\n","# sentence_embeddings = bert_model.encode(book['subject'])\n","# sentence_embeddings.shape #(983, 768)\n","sentence_embeddings[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-4.77335542e-01,  3.71796191e-01,  4.22544748e-01,  7.59998620e-01,\n","       -3.85853112e-01, -7.17986748e-02,  4.27637130e-01, -1.43503487e-01,\n","        2.13111416e-01, -4.03409362e-01,  1.65444076e-01,  3.80740166e-01,\n","        1.42300367e-01, -4.24716651e-01, -5.30597329e-01,  7.15721846e-01,\n","       -7.49361217e-01, -4.26458329e-01,  1.04344428e-01, -4.20641869e-01,\n","        2.94024169e-01, -4.12547678e-01,  1.95334524e-01,  1.18603818e-01,\n","        7.17893004e-01,  5.93436837e-01, -5.44176959e-02, -3.98434252e-01,\n","       -3.02409202e-01,  4.67815667e-01,  2.02830911e-01,  2.48822168e-01,\n","       -3.70882332e-01, -3.65570247e-01, -4.82681423e-01, -8.54683295e-03,\n","        4.74348456e-01,  5.52435398e-01,  3.30556184e-01,  1.55728921e-01,\n","        3.39899302e-01,  4.12307501e-01,  3.81828755e-01, -4.35026467e-01,\n","       -1.36849970e-01,  8.58883485e-02, -1.17381728e+00, -9.22385678e-02,\n","        7.37570301e-02, -3.23347092e-01, -5.13782680e-01,  2.82991510e-02,\n","        1.95974156e-01,  7.33809888e-01, -4.56527263e-01,  2.72889853e-01,\n","        3.66415441e-01, -3.94910961e-01, -1.06571443e-01, -8.52712870e-01,\n","       -1.10598910e+00, -1.50624603e-01, -1.47192329e-01,  3.78323972e-01,\n","        9.44349158e-04, -1.86451316e-01,  7.87378371e-01, -2.46208534e-02,\n","       -5.27974188e-01, -3.67795341e-02, -2.35295668e-02, -3.62425923e-01,\n","       -9.62379873e-02,  8.26641440e-01,  5.12931883e-01,  3.51202339e-02,\n","       -1.49060339e-01, -1.85295120e-02,  2.47228131e-01,  6.14679039e-01,\n","        1.65070258e-02, -3.86057347e-01, -4.76410449e-01,  3.84994596e-02,\n","        6.17244482e-01,  2.76828647e-01,  6.88374937e-01,  2.62798429e-01,\n","       -5.28437436e-01, -1.98687632e-02, -2.25778431e-01,  5.31744584e-02,\n","       -1.64799914e-01, -6.75228059e-01, -2.48678133e-01,  1.11226626e-01,\n","        5.14865696e-01, -4.87599224e-01, -9.67181697e-02,  6.83020651e-02,\n","       -5.46249747e-01, -5.19375265e-01,  5.32042742e-01, -5.58175564e-01,\n","       -5.21665335e-01, -1.69913411e-01,  2.42420673e-01,  3.38062465e-01,\n","        1.95339248e-01,  2.39782274e-01,  2.07787290e-01, -7.62430429e-01,\n","        3.95670176e-01,  4.03900594e-01, -6.20270073e-02, -5.21440268e-01,\n","       -5.16384363e-01,  7.14562654e-01,  2.62558311e-01,  5.11333525e-01,\n","       -4.30016965e-01,  1.46649450e-01, -3.73747945e-01,  1.81668416e-01,\n","        3.66177522e-02,  2.46486947e-01, -9.08200517e-02,  2.20112264e-01,\n","       -1.07299320e-01,  8.01852066e-03,  4.27310675e-01, -4.73125577e-01,\n","        4.94893163e-01, -2.62112349e-01, -3.82577807e-01,  5.73902071e-01,\n","       -6.00029007e-02, -7.81995282e-02, -3.50606292e-02,  2.53261834e-01,\n","       -6.46367297e-02, -2.33684212e-01, -6.75038770e-02, -1.68307602e-01,\n","       -1.92819405e-02,  1.51939690e-01, -2.12716721e-02,  4.53098297e-01,\n","        5.39933205e-01,  1.63025528e-01,  1.72383830e-01,  1.94720820e-01,\n","       -6.56553864e-01, -4.78842765e-01, -2.08820194e-01,  8.48074555e-02,\n","       -3.33228648e-01,  1.52797163e-01,  4.25116032e-01,  1.31161630e-01,\n","       -2.17394173e-01,  9.31896195e-02,  1.87607542e-01,  6.64162517e-01,\n","        3.64890665e-01, -2.10361570e-01,  8.18061531e-01, -7.26794839e-01,\n","       -2.75783986e-01,  4.45930600e-01, -1.59415513e-01, -4.34058875e-01,\n","       -1.22267574e-01,  7.35117018e-01, -2.06682459e-01,  3.65223080e-01,\n","        6.41774416e-01,  2.38823503e-01,  2.04681218e-01, -9.50935364e-01,\n","       -2.16096178e-01, -1.85020790e-01, -3.53751421e-01, -1.27303615e-01,\n","       -4.39061448e-02, -2.55207658e-01,  8.36854577e-02, -7.19332218e-01,\n","        2.94780493e-01,  8.48450363e-02, -4.87509221e-01,  1.51919380e-01,\n","        1.80775487e+00,  1.44117057e-01,  1.28786266e+00,  6.33285701e-01,\n","       -3.48086089e-01,  6.34158194e-01, -6.33235872e-02,  5.64002216e-01,\n","        3.79407376e-01,  2.32002646e-01,  2.10882381e-01,  6.96307123e-02,\n","       -4.27249670e-01,  3.59224617e-01, -2.25831911e-01,  5.42616248e-01,\n","       -3.03302050e-01, -1.64773464e-01, -3.42992246e-01,  3.23264569e-01,\n","        9.85750929e-02,  1.99860185e-02, -8.00900459e-02, -8.30847099e-02,\n","        5.75156987e-01, -4.09024626e-01,  6.21827185e-01,  3.75537038e-01,\n","        2.86644280e-01, -5.09463727e-01,  1.60904586e-01, -2.06021085e-01,\n","       -3.25757623e-01,  1.12883896e-01,  2.41707593e-01,  4.65380102e-01,\n","        4.80082273e-01,  1.78518351e-02,  1.79746244e-02,  3.29278827e-01,\n","        5.87011687e-02, -1.63164362e-01,  6.01227701e-01, -7.39430711e-02,\n","       -7.18866810e-02,  6.66390538e-01,  1.18087314e-01, -1.98562533e-01,\n","        5.22841215e-01, -2.00114921e-02, -1.61798701e-01,  1.19468287e-01,\n","        1.33461252e-01,  5.02184108e-02, -1.91395223e-01,  2.78964192e-01,\n","        1.99924812e-01, -2.32372090e-01, -9.01794061e-02, -1.32852579e-02,\n","       -3.36103141e-01, -3.77985686e-01,  2.01012090e-01, -1.15261681e-01,\n","       -1.95955694e-01, -3.70956510e-01,  5.47113895e-01, -1.83043003e-01,\n","       -1.22336291e-01, -1.09883678e+00,  1.50876328e-01, -3.59740764e-01,\n","        3.97406697e-01, -4.68997121e-01,  1.47068068e-01, -3.32999885e-01,\n","       -6.02741539e-01,  3.35718721e-01, -9.53845009e-02,  1.37125880e-01,\n","        2.96866536e-01,  3.37973535e-02, -2.48680532e-01,  3.11190963e-01,\n","       -2.05609709e-01, -7.11518228e-01, -7.78117001e-01,  4.91342813e-01,\n","       -7.01906025e-01, -5.96731722e-01, -8.51094365e-01, -5.95553033e-02,\n","        2.50152886e-01,  1.11779884e-01,  7.46012211e-01, -5.43331802e-01,\n","       -6.35585546e-01,  1.98914379e-01, -9.25075337e-02, -4.49459463e-01,\n","       -3.10215205e-01, -1.39448911e-01,  6.33510828e-01,  2.26046443e-01,\n","       -9.57918838e-02, -8.97223055e-02, -1.67750701e-01, -4.19839144e-01,\n","        2.33032763e-01,  1.80558741e-01, -4.12993819e-01,  4.12281543e-01,\n","       -6.61756873e-01, -8.08309913e-01,  1.36585787e-01,  2.59627521e-01,\n","       -1.41801167e+00, -5.62272370e-01, -5.35814404e-01,  1.66421637e-01,\n","       -1.91711381e-01,  3.09168547e-01, -1.76339239e-01, -8.84007514e-02,\n","        3.95726591e-01, -1.72935292e-01, -1.76858678e-01,  1.83803812e-01,\n","       -6.98357761e-01,  1.89367071e-01, -1.77019253e-01,  2.61789054e-01,\n","       -7.87216902e-01,  4.91203070e-01, -4.45558913e-02,  5.21352254e-02,\n","        1.66553576e-02, -1.71255246e-01,  3.13850611e-01,  9.15876031e-02,\n","        9.48082507e-02,  1.23251371e-01, -5.10196209e-01,  5.40433049e-01,\n","       -9.29993242e-02,  2.36813009e-01, -1.58190131e-01, -7.11170495e-01,\n","        2.35493854e-01,  7.83270821e-02,  2.73857087e-01, -1.91638235e-03,\n","        1.01986742e+00, -2.32398994e-02, -1.38876602e-01, -1.24292813e-01,\n","        5.00885248e-02,  7.03349769e-01, -4.24697958e-02,  9.73835886e-02,\n","        6.16623759e-01, -5.92193127e-01,  4.66383904e-01,  3.30172539e-01,\n","       -8.95138383e-02, -9.27467942e-02, -5.77067375e-01,  1.87206224e-01,\n","       -3.20322812e-01, -1.71695769e-01,  9.35175121e-02,  2.60923952e-01,\n","       -4.92927790e-01, -9.60747838e-01,  3.52346063e-01,  4.26002800e-01,\n","       -3.51120234e-02, -6.45814002e-01, -3.29407096e-01,  2.93880135e-01,\n","       -3.93977344e-01, -4.99294251e-01, -1.45585716e-01,  2.51446575e-01,\n","       -4.58463758e-01, -2.12280467e-01,  1.45261124e-01,  7.39690304e-01,\n","        3.56622040e-01, -3.08128387e-01, -2.45052334e-02, -2.30162978e-01,\n","       -2.77929544e-01,  4.73166704e-01, -3.30542654e-01,  4.03024524e-01,\n","       -1.52869865e-01, -1.60117060e-01,  1.00456998e-01,  8.05110037e-02,\n","        6.74952090e-01,  6.08167470e-01,  1.79138869e-01, -6.98258877e-02,\n","        4.61171977e-02,  2.02234179e-01,  9.79186445e-02, -2.22900271e-01,\n","       -1.51063994e-01,  5.17229736e-01,  7.38629401e-01,  3.22260141e-01,\n","       -3.47526938e-01, -8.46307695e-01,  5.19358575e-01, -1.01085603e-01,\n","        1.08453846e+00, -4.21598047e-01,  5.30105829e-01,  6.79586709e-01,\n","        4.56833661e-01,  2.06762436e-03, -4.20021832e-01, -1.02945574e-01,\n","        1.81770608e-01, -1.75184935e-01, -8.04009378e-01,  4.51142669e-01,\n","       -3.86587799e-01,  4.74065185e-01,  8.80069956e-02, -2.45118633e-01,\n","       -3.12214315e-01,  4.48190600e-01,  2.88965721e-02, -3.02351892e-01,\n","       -7.48993875e-03,  2.73764253e-01,  4.56992686e-01, -2.87892312e-01,\n","       -1.11081553e+00, -4.13541943e-01, -2.88202856e-02, -1.53201461e-01,\n","        3.62649828e-01,  2.48895660e-01,  8.58035684e-02, -3.02760422e-01,\n","        5.12828350e-01,  5.64112179e-02,  1.73457548e-01,  6.87326267e-02,\n","        1.95175245e-01, -7.22180009e-02, -2.46024374e-02,  1.21161267e-01,\n","        4.34882671e-01, -7.31137767e-02, -2.09629670e-01, -4.52271968e-01,\n","        4.30448085e-01, -5.44421375e-01, -3.26163173e-01,  1.42512962e-01,\n","       -4.22057420e-01, -4.47974086e-01,  3.48140635e-02, -7.04462528e-01,\n","        3.30999494e-02, -2.24115759e-01,  3.43260281e-02, -7.80544102e-01,\n","       -2.38012522e-01,  9.07463670e-01, -2.86120921e-01, -2.03100275e-02,\n","        4.98099178e-01,  5.08644342e-01, -1.07606813e-01, -4.40496683e-01,\n","        3.48631293e-02, -5.01946509e-01, -9.25715864e-02,  3.18555415e-01,\n","       -1.07780194e+00,  1.94340855e-01,  1.94038779e-01,  1.22464791e-01,\n","       -1.50073767e-02,  6.66279346e-02,  1.48692414e-01, -9.87173080e-01,\n","       -3.50215197e-01, -1.09873407e-01,  1.61199003e-01,  5.23159921e-01,\n","       -2.15495944e-01, -9.70197856e-01,  5.22532277e-02,  1.65458381e-01,\n","       -1.03319839e-01, -1.04762994e-01,  7.24663675e-01,  2.18905628e-01,\n","       -1.54996693e-01, -1.16387561e-01,  1.75375134e-01, -7.59624124e-01,\n","        6.73372820e-02, -2.60876238e-01, -2.57082760e-01,  5.73965430e-01,\n","        2.51306355e-01, -2.00583190e-01, -1.86965186e-02, -1.03315830e-01,\n","       -7.16079891e-01,  3.95219684e-01, -1.55114502e-01, -6.75831556e-01,\n","       -6.60243332e-02,  4.68456566e-01,  1.54988006e-01, -8.75923514e-01,\n","        1.65214971e-01,  2.79956520e-01, -6.41476035e-01, -6.71202481e-01,\n","        1.07166313e-01, -1.60499275e-01,  2.42782593e-01, -6.05303705e-01,\n","        4.06928331e-01, -3.90366316e-02, -7.49753118e-02, -7.99296647e-02,\n","        1.08666375e-01,  4.44650790e-03, -7.98835456e-01,  9.73172206e-03,\n","        5.21221995e-01,  7.69093394e-01, -5.75846769e-02, -5.42076468e-01,\n","       -5.03602505e-01,  2.62200534e-01, -9.31383893e-02, -6.80930316e-01,\n","        1.24974795e-01,  4.84928936e-01,  1.68684408e-01, -4.45099436e-02,\n","        1.71979681e-01,  1.75032496e-01,  1.28899455e-01, -8.82182345e-02,\n","        4.05107617e-01, -3.28731924e-01, -9.52371582e-02, -6.85222566e-01,\n","        5.75561345e-01, -1.64527535e-01,  6.90817118e-01, -4.12597388e-01,\n","        5.56152835e-02, -1.73798844e-01,  1.49894357e-01,  4.40165401e-01,\n","       -5.81653118e-01,  3.10233384e-01,  8.79031718e-02, -7.97484159e-01,\n","        8.23041916e-01,  4.73009013e-02, -1.94237411e-01,  4.19649594e-02,\n","       -3.51332635e-01,  1.83216631e-01,  1.78516135e-01, -4.32052761e-01,\n","       -4.95544672e-01,  5.36480129e-01,  9.37759429e-02, -9.97267008e-01,\n","       -3.09849322e-01,  4.16127801e-01,  6.07405245e-01, -4.44729656e-01,\n","        7.98213258e-02, -2.39344239e-01,  5.34674883e-01,  2.57259130e-01,\n","       -6.96490109e-02,  1.01018417e+00, -7.37491772e-02,  8.88692498e-01,\n","        2.55613332e-03, -1.42088279e-01, -9.03059602e-01, -3.20878714e-01,\n","        1.72487214e-01,  3.94042522e-01,  4.68489379e-01,  3.63658547e-01,\n","        1.86264694e-01,  7.50540316e-01, -2.37192348e-01, -3.70654136e-01,\n","       -2.41339639e-01, -9.07271266e-01,  2.35370770e-01,  3.23875427e-01,\n","       -1.07814893e-01,  1.78693563e-01,  2.34653324e-01,  4.53073978e-02,\n","       -7.32294858e-01,  4.99488533e-01,  3.88467759e-01, -8.83896172e-01,\n","       -1.28637850e-01, -1.22812344e-02,  4.54030745e-02, -5.60279667e-01,\n","       -1.45092621e-01,  1.33350775e-01, -6.59491941e-02,  8.16770196e-02,\n","        4.47529703e-01, -1.11377217e-01,  1.47800297e-01, -8.24677587e-01,\n","        3.36053699e-01, -6.85402751e-01, -1.59279287e-01,  4.26374197e-01,\n","       -1.34411588e-01, -2.45295316e-01,  2.76685834e-01, -3.39447618e-01,\n","       -2.23531231e-01,  1.82181165e-01,  2.55175143e-01,  5.71737826e-01,\n","       -8.85439515e-01,  6.11772299e-01,  1.04569793e+00,  3.18432748e-01,\n","       -5.77293158e-01, -4.11857635e-01,  7.47558624e-02, -1.64861754e-01,\n","        5.85277379e-01, -4.44527805e-01, -8.16544071e-02,  3.90449136e-01,\n","        5.22573709e-01, -2.21443009e-02, -1.08098447e-01,  4.89931881e-01,\n","       -6.66024446e-01,  2.85184205e-01, -9.38989818e-01, -1.88316971e-01,\n","       -3.54008555e-01,  4.28840481e-02,  8.26592684e-01,  5.63592136e-01,\n","       -2.45894998e-01, -2.61930525e-01,  1.89591840e-01, -1.05931148e-01,\n","        3.19696158e-01, -5.15785992e-01,  2.50406176e-01,  5.90383708e-01,\n","        2.70213693e-01, -1.06922546e-02,  9.22701042e-03,  1.02228917e-01,\n","       -4.02397245e-01,  2.64030874e-01,  5.98822653e-01, -8.13833773e-02,\n","        1.37449741e-01, -7.30793253e-02, -5.64368606e-01, -1.18260229e+00,\n","       -2.94354051e-01, -3.22169811e-01,  6.68351352e-02, -1.05616324e-01,\n","       -6.08348325e-02,  1.88263848e-01,  8.43574166e-01,  2.53914744e-01,\n","       -1.69726312e-01, -1.72502115e-01, -1.28080044e-02, -4.81367111e-03,\n","       -1.81307584e-01, -7.01590300e-01,  5.84168136e-02, -4.89273489e-01,\n","       -8.63954723e-02,  1.51996806e-01, -1.01783657e+00,  1.24253474e-01,\n","        1.74753532e-01,  4.81483713e-02, -1.88174501e-01,  3.45205218e-02,\n","        1.55768394e-01,  6.67336881e-01, -7.74731711e-02, -1.02165908e-01,\n","       -1.14629744e-03, -1.25981763e-01,  1.92002147e-01, -7.91307747e-01,\n","        8.20857063e-02,  1.36805221e-01, -1.44924596e-01,  7.86279738e-01,\n","        6.55215383e-01, -4.49718922e-01, -6.07688308e-01, -8.44318494e-02,\n","        4.64649498e-01, -6.19466484e-01, -8.60620260e-01, -3.95691305e-01,\n","        4.71026987e-01, -2.88502604e-01,  6.18291020e-01, -7.95050561e-01,\n","       -2.32872277e-01,  5.45100160e-02, -4.85843778e-01, -5.73606551e-01,\n","        2.05925182e-01,  1.53596610e-01, -5.36167584e-02, -2.04741970e-01,\n","       -3.22577029e-01,  7.38240555e-02,  2.70885706e-01,  4.08206135e-02,\n","       -5.31793594e-01, -3.69285226e-01, -3.94985378e-01, -5.99744797e-01,\n","       -4.68150049e-01, -5.51465273e-01, -7.16217220e-01, -2.30099298e-02,\n","        5.28731905e-02, -1.89758897e-01, -5.18933594e-01,  2.79005408e-01,\n","        8.87730345e-02,  4.41091388e-01, -3.68211448e-01,  1.16590463e-01,\n","        5.04692316e-01, -3.56489122e-02, -4.83345330e-01, -5.02156794e-01,\n","        1.03142560e+00, -2.05120206e-01, -2.59154171e-01, -8.38013366e-02,\n","       -8.83986056e-02, -7.98147678e-01,  3.64760906e-01,  3.58513266e-01],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"WArVb5KayqyJ"},"source":["### 5. Create the deep learning model using BERT "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlYM2EAuAY1k","executionInfo":{"status":"ok","timestamp":1608268028761,"user_tz":-540,"elapsed":709,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}},"outputId":"581b864c-a756-4b74-c31f-98d60a95c3e1"},"source":["# sentence_embeddings[0]\n","#student_book\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Flatten,BatchNormalization, Dropout, Reshape\n","\n","model = Sequential()        #input = number of books #output dim = embedding shape  #input_length : max_len since sentence\n","genre_embeddings  = Embedding(input_dim = sentence_embeddings.shape[0], #983  \n","                              output_dim=sentence_embeddings.shape[1], #768\n","                              input_length= max_len, \n","                              weights = [sentence_embeddings],trainable=True)\n","model.add(genre_embeddings)\n","model.add( Flatten() )\n","model.add(Dense(900, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(Dense(990, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(Dense(983, activation='softmax')) \n","model.compile(optimizer='adam', loss='categorical_crossentropy',\tmetrics=[\"accuracy\"])\n","\n","model.summary()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 55, 768)           754944    \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 42240)             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 900)               38016900  \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 900)               3600      \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 900)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 990)               891990    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 990)               3960      \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 990)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 983)               974153    \n","=================================================================\n","Total params: 40,645,547\n","Trainable params: 40,641,767\n","Non-trainable params: 3,780\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bF9B2FMLItyq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608268128021,"user_tz":-540,"elapsed":97607,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}},"outputId":"307ff2fd-c9a9-4b72-b689-df255d1ae992"},"source":["history = model.fit(pad_new,\n","                    train_y,\n","                    epochs=100,\n","                    batch_size=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","51/51 [==============================] - 2s 19ms/step - loss: 7.9187 - accuracy: 0.0000e+00\n","Epoch 2/100\n","51/51 [==============================] - 1s 19ms/step - loss: 7.1037 - accuracy: 0.0045\n","Epoch 3/100\n","51/51 [==============================] - 1s 19ms/step - loss: 6.2974 - accuracy: 0.0400\n","Epoch 4/100\n","51/51 [==============================] - 1s 19ms/step - loss: 5.6226 - accuracy: 0.0618\n","Epoch 5/100\n","51/51 [==============================] - 1s 19ms/step - loss: 5.1674 - accuracy: 0.0938\n","Epoch 6/100\n","51/51 [==============================] - 1s 22ms/step - loss: 4.2286 - accuracy: 0.1895\n","Epoch 7/100\n","51/51 [==============================] - 1s 19ms/step - loss: 3.8633 - accuracy: 0.2289\n","Epoch 8/100\n","51/51 [==============================] - 1s 19ms/step - loss: 3.3284 - accuracy: 0.2957\n","Epoch 9/100\n","51/51 [==============================] - 1s 19ms/step - loss: 3.0448 - accuracy: 0.3762\n","Epoch 10/100\n","51/51 [==============================] - 1s 19ms/step - loss: 2.3755 - accuracy: 0.4891\n","Epoch 11/100\n","51/51 [==============================] - 1s 19ms/step - loss: 2.0623 - accuracy: 0.4998\n","Epoch 12/100\n","51/51 [==============================] - 1s 18ms/step - loss: 1.8169 - accuracy: 0.5973\n","Epoch 13/100\n","51/51 [==============================] - 1s 18ms/step - loss: 1.6778 - accuracy: 0.6718\n","Epoch 14/100\n","51/51 [==============================] - 1s 19ms/step - loss: 1.5619 - accuracy: 0.6777\n","Epoch 15/100\n","51/51 [==============================] - 1s 19ms/step - loss: 1.2850 - accuracy: 0.6733\n","Epoch 16/100\n","51/51 [==============================] - 1s 18ms/step - loss: 1.2898 - accuracy: 0.6675\n","Epoch 17/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.9115 - accuracy: 0.8143\n","Epoch 18/100\n","51/51 [==============================] - 1s 19ms/step - loss: 1.0761 - accuracy: 0.7363\n","Epoch 19/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.7721 - accuracy: 0.8225\n","Epoch 20/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.7532 - accuracy: 0.8330\n","Epoch 21/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.7881 - accuracy: 0.7976\n","Epoch 22/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.8211 - accuracy: 0.7727\n","Epoch 23/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.7144 - accuracy: 0.7821\n","Epoch 24/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.6497 - accuracy: 0.8452\n","Epoch 25/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.5857 - accuracy: 0.8574\n","Epoch 26/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.6797 - accuracy: 0.8433\n","Epoch 27/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.5671 - accuracy: 0.8389\n","Epoch 28/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.7741 - accuracy: 0.7725\n","Epoch 29/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.6520 - accuracy: 0.7805\n","Epoch 30/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.4939 - accuracy: 0.8545\n","Epoch 31/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.4771 - accuracy: 0.8856\n","Epoch 32/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.5436 - accuracy: 0.8815\n","Epoch 33/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.5877 - accuracy: 0.8382\n","Epoch 34/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.5759 - accuracy: 0.8400\n","Epoch 35/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.5202 - accuracy: 0.8407\n","Epoch 36/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.4799 - accuracy: 0.8690\n","Epoch 37/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.3763 - accuracy: 0.9038\n","Epoch 38/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.4853 - accuracy: 0.8735\n","Epoch 39/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.3236 - accuracy: 0.9120\n","Epoch 40/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2676 - accuracy: 0.9243\n","Epoch 41/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.3487 - accuracy: 0.8787\n","Epoch 42/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.3372 - accuracy: 0.9047\n","Epoch 43/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.3467 - accuracy: 0.9018\n","Epoch 44/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.2456 - accuracy: 0.9251\n","Epoch 45/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1759 - accuracy: 0.9627\n","Epoch 46/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2169 - accuracy: 0.9243\n","Epoch 47/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.2895 - accuracy: 0.9118\n","Epoch 48/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2170 - accuracy: 0.9294\n","Epoch 49/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2480 - accuracy: 0.9403\n","Epoch 50/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.2509 - accuracy: 0.9465\n","Epoch 51/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1809 - accuracy: 0.9510\n","Epoch 52/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1765 - accuracy: 0.9651\n","Epoch 53/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.2703 - accuracy: 0.9335\n","Epoch 54/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1833 - accuracy: 0.9353\n","Epoch 55/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.2807 - accuracy: 0.9136\n","Epoch 56/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1864 - accuracy: 0.9395\n","Epoch 57/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1732 - accuracy: 0.9355\n","Epoch 58/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1292 - accuracy: 0.9544\n","Epoch 59/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2249 - accuracy: 0.9407\n","Epoch 60/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1853 - accuracy: 0.9497\n","Epoch 61/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2753 - accuracy: 0.9139\n","Epoch 62/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2228 - accuracy: 0.9250\n","Epoch 63/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1522 - accuracy: 0.9699\n","Epoch 64/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1722 - accuracy: 0.9678\n","Epoch 65/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1608 - accuracy: 0.9551\n","Epoch 66/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2793 - accuracy: 0.9235\n","Epoch 67/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1554 - accuracy: 0.9375\n","Epoch 68/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1661 - accuracy: 0.9354\n","Epoch 69/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2598 - accuracy: 0.9160\n","Epoch 70/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1095 - accuracy: 0.9743\n","Epoch 71/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2073 - accuracy: 0.9489\n","Epoch 72/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1710 - accuracy: 0.9385\n","Epoch 73/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1955 - accuracy: 0.9243\n","Epoch 74/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2059 - accuracy: 0.9442\n","Epoch 75/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1721 - accuracy: 0.9296\n","Epoch 76/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1124 - accuracy: 0.9688\n","Epoch 77/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1286 - accuracy: 0.9710\n","Epoch 78/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1447 - accuracy: 0.9501\n","Epoch 79/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1565 - accuracy: 0.9581\n","Epoch 80/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1221 - accuracy: 0.9663\n","Epoch 81/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1075 - accuracy: 0.9507\n","Epoch 82/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1421 - accuracy: 0.9676\n","Epoch 83/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1379 - accuracy: 0.9565\n","Epoch 84/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.2195 - accuracy: 0.9511\n","Epoch 85/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1222 - accuracy: 0.9756\n","Epoch 86/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.2398 - accuracy: 0.9209\n","Epoch 87/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1977 - accuracy: 0.9293\n","Epoch 88/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1542 - accuracy: 0.9512\n","Epoch 89/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1841 - accuracy: 0.9484\n","Epoch 90/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2128 - accuracy: 0.9458\n","Epoch 91/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1176 - accuracy: 0.9690\n","Epoch 92/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1153 - accuracy: 0.9792\n","Epoch 93/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1883 - accuracy: 0.9531\n","Epoch 94/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1463 - accuracy: 0.9540\n","Epoch 95/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1196 - accuracy: 0.9684\n","Epoch 96/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.2798 - accuracy: 0.9342\n","Epoch 97/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1041 - accuracy: 0.9606\n","Epoch 98/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.1507 - accuracy: 0.9475\n","Epoch 99/100\n","51/51 [==============================] - 1s 18ms/step - loss: 0.1410 - accuracy: 0.9414\n","Epoch 100/100\n","51/51 [==============================] - 1s 19ms/step - loss: 0.2405 - accuracy: 0.9248\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nI250xkJywpE"},"source":["### 6. Test out the model (this case I used the training values, so its almost 100%)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VyNqTaxHHLtR","executionInfo":{"status":"ok","timestamp":1608268181309,"user_tz":-540,"elapsed":937,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}},"outputId":"452b4df5-ca1b-4734-8942-e81199cdce54"},"source":["# model.evaluate(student_book.iloc[0], y.iloc[0])\n","yprob= model.predict(pad_new[:2])\n","yprob.argmax(axis=-1) #\n","model.predict_classes(pad_new[:2])\n","# yprob.shape #(2, 983)\n","# yprob"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["array([460, 835])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"r6kLIHbCH_PS","executionInfo":{"status":"ok","timestamp":1608267658080,"user_tz":-540,"elapsed":672,"user":{"displayName":"Jane Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1RzZfGrZlm3rXI_UeksLJhJRcXZwvKSFyYs0hHXQ=s64","userId":"16603819653710827352"}},"outputId":"bc6952d6-c661-4f0c-b720-d09144b80ec1"},"source":["train_y.iloc[:2, 460:] #460 predict \n","train_y.iloc[:2, 830:] #835 predict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>830</th>\n","      <th>831</th>\n","      <th>832</th>\n","      <th>833</th>\n","      <th>834</th>\n","      <th>835</th>\n","      <th>836</th>\n","      <th>837</th>\n","      <th>838</th>\n","      <th>839</th>\n","      <th>840</th>\n","      <th>841</th>\n","      <th>842</th>\n","      <th>843</th>\n","      <th>844</th>\n","      <th>845</th>\n","      <th>846</th>\n","      <th>847</th>\n","      <th>848</th>\n","      <th>849</th>\n","      <th>850</th>\n","      <th>851</th>\n","      <th>852</th>\n","      <th>853</th>\n","      <th>854</th>\n","      <th>855</th>\n","      <th>856</th>\n","      <th>857</th>\n","      <th>858</th>\n","      <th>859</th>\n","      <th>860</th>\n","      <th>861</th>\n","      <th>862</th>\n","      <th>863</th>\n","      <th>864</th>\n","      <th>865</th>\n","      <th>866</th>\n","      <th>867</th>\n","      <th>868</th>\n","      <th>869</th>\n","      <th>...</th>\n","      <th>943</th>\n","      <th>944</th>\n","      <th>945</th>\n","      <th>946</th>\n","      <th>947</th>\n","      <th>948</th>\n","      <th>949</th>\n","      <th>950</th>\n","      <th>951</th>\n","      <th>952</th>\n","      <th>953</th>\n","      <th>954</th>\n","      <th>955</th>\n","      <th>956</th>\n","      <th>957</th>\n","      <th>958</th>\n","      <th>959</th>\n","      <th>960</th>\n","      <th>961</th>\n","      <th>962</th>\n","      <th>963</th>\n","      <th>964</th>\n","      <th>965</th>\n","      <th>966</th>\n","      <th>967</th>\n","      <th>968</th>\n","      <th>969</th>\n","      <th>970</th>\n","      <th>971</th>\n","      <th>972</th>\n","      <th>973</th>\n","      <th>974</th>\n","      <th>975</th>\n","      <th>976</th>\n","      <th>977</th>\n","      <th>978</th>\n","      <th>979</th>\n","      <th>980</th>\n","      <th>981</th>\n","      <th>982</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 153 columns</p>\n","</div>"],"text/plain":["   830  831  832  833  834  835  836  ...  976  977  978  979  980  981  982\n","0    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n","1    0    0    0    0    0    1    0  ...    0    0    0    0    0    0    0\n","\n","[2 rows x 153 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"XfHV_OGzy5YM"},"source":["## cf) for visualization we need to make the embeddings with this formula\n"]},{"cell_type":"code","metadata":{"id":"xGEF9eJq6aWj"},"source":["#for visualization \n","# Convert NumPy array of embedding into data frame\n","embedding_df = pd.DataFrame(sentence_embeddings)\n","\n","# Save dataframe as as TSV file without any index and header\n","embedding_df.to_csv('output.tsv', sep='\\t', index=None, header=None)\n","book.to_csv('metadata.tsv', index=False, sep='\\t')"],"execution_count":null,"outputs":[]}]}